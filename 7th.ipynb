{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import yfinance as yf\n",
    "import keras \n",
    "import os\n",
    "import tensorflow\n",
    "import datetime \n",
    "import requests\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Dense\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Activation\n",
    "from keras import optimizers\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[3.09577038e-04],\n",
       "         [2.83417097e-04],\n",
       "         [2.48533581e-04],\n",
       "         ...,\n",
       "         [2.51314495e-04],\n",
       "         [2.40308723e-04],\n",
       "         [2.45811625e-04]],\n",
       " \n",
       "        [[2.83417097e-04],\n",
       "         [2.48533581e-04],\n",
       "         [2.59433515e-04],\n",
       "         ...,\n",
       "         [2.40308723e-04],\n",
       "         [2.45811625e-04],\n",
       "         [2.49480110e-04]],\n",
       " \n",
       "        [[2.48533581e-04],\n",
       "         [2.59433515e-04],\n",
       "         [2.72517314e-04],\n",
       "         ...,\n",
       "         [2.45811625e-04],\n",
       "         [2.49480110e-04],\n",
       "         [2.40308723e-04]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[2.41532410e-01],\n",
       "         [2.41047347e-01],\n",
       "         [2.45865133e-01],\n",
       "         ...,\n",
       "         [1.71949296e-01],\n",
       "         [1.71934550e-01],\n",
       "         [1.64214660e-01]],\n",
       " \n",
       "        [[2.41047347e-01],\n",
       "         [2.45865133e-01],\n",
       "         [2.43914318e-01],\n",
       "         ...,\n",
       "         [1.71934550e-01],\n",
       "         [1.64214660e-01],\n",
       "         [1.67514764e-01]],\n",
       " \n",
       "        [[2.45865133e-01],\n",
       "         [2.43914318e-01],\n",
       "         [2.40432973e-01],\n",
       "         ...,\n",
       "         [1.64214660e-01],\n",
       "         [1.67514764e-01],\n",
       "         [1.61415468e-01]]]),\n",
       " array([[[0.32222076],\n",
       "         [0.32192563],\n",
       "         [0.32501206],\n",
       "         ...,\n",
       "         [0.25385768],\n",
       "         [0.2502071 ],\n",
       "         [0.27204858]],\n",
       " \n",
       "        [[0.32192563],\n",
       "         [0.32501206],\n",
       "         [0.32276184],\n",
       "         ...,\n",
       "         [0.2502071 ],\n",
       "         [0.27204858],\n",
       "         [0.26889575]],\n",
       " \n",
       "        [[0.32501206],\n",
       "         [0.32276184],\n",
       "         [0.32659837],\n",
       "         ...,\n",
       "         [0.27204858],\n",
       "         [0.26889575],\n",
       "         [0.27578221]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.92557036],\n",
       "         [0.9918392 ],\n",
       "         [0.98077465],\n",
       "         ...,\n",
       "         [0.86307501],\n",
       "         [0.80545737],\n",
       "         [0.79114515]],\n",
       " \n",
       "        [[0.9918392 ],\n",
       "         [0.98077465],\n",
       "         [0.94899488],\n",
       "         ...,\n",
       "         [0.80545737],\n",
       "         [0.79114515],\n",
       "         [0.74083114]],\n",
       " \n",
       "        [[0.98077465],\n",
       "         [0.94899488],\n",
       "         [0.9478398 ],\n",
       "         ...,\n",
       "         [0.79114515],\n",
       "         [0.74083114],\n",
       "         [0.76886536]]]),\n",
       " array([[0.00024948],\n",
       "        [0.00024031],\n",
       "        [0.00024031],\n",
       "        ...,\n",
       "        [0.16751476],\n",
       "        [0.16141547],\n",
       "        [0.16801567]]),\n",
       " array([[0.26889575],\n",
       "        [0.27578221],\n",
       "        [0.27777345],\n",
       "        ...,\n",
       "        [0.74083114],\n",
       "        [0.76886536],\n",
       "        [0.75411052]]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#takes any ticker and returns X as past # days and Y as tmr's price, split into train and test\n",
    "def DataPrep(ticker='aapl',daysago=100,split=0.9):\n",
    "    df = yf.Ticker(ticker.upper()).history(period='max')\n",
    "    if df.shape[1] == 7:\n",
    "        df = df.drop(columns=['Dividends','Stock Splits'])\n",
    "    df = df.drop(columns=['Open','High','Low','Volume'])\n",
    "    for i in range(daysago,-2,-1):\n",
    "        df['{}daysago'.format(i)] = df['Close'].shift(i)\n",
    "        df = df.copy()\n",
    "    df = df.drop(columns=['Close'])\n",
    "    df = df.dropna()\n",
    "    sc = MinMaxScaler(feature_range=(0,1))\n",
    "    df_scaled = sc.fit_transform(df)\n",
    "    X,Y = df_scaled[:,:daysago+1],df_scaled[:,-1]\n",
    "    split = int(len(X)*split)\n",
    "    X_train, X_test, Y_train, Y_test = X[:split], X[split:], Y[:split], Y[split:]\n",
    "    X_train, X_test = X_train.reshape((-1,daysago+1,1)), X_test.reshape((-1,daysago+1,1))\n",
    "    Y_train, Y_test = Y_train.reshape((-1,1)), Y_test.reshape((-1,1))\n",
    "    return X_train, X_test, Y_train, Y_test\n",
    "\n",
    "#takes any list of tickers, compiles x_train, x_test, y_train, y_test, @ a set daysago and split\n",
    "def CompileData(tickers=['aapl','nvda'],daysago=100,split=0.9):\n",
    "    X_train,X_test,Y_train,Y_test = [],[],[],[]\n",
    "    X_train,X_test,Y_train,Y_test = np.array(X_train).reshape(-1,daysago+1,1),np.array(X_test).reshape(-1,daysago+1,1), np.array(Y_train).reshape(-1,1), np.array(Y_test).reshape(-1,1)\n",
    "    for ticker in tickers:\n",
    "        dataprep = DataPrep(ticker,daysago,split)\n",
    "        X_train = np.append(X_train,dataprep[0],axis=0)\n",
    "        X_test = np.append(X_test,dataprep[1],axis=0)\n",
    "        Y_train = np.append(Y_train,dataprep[2],axis=0)\n",
    "        Y_test = np.append(Y_test,dataprep[3],axis=0)\n",
    "    return X_train, X_test, Y_train, Y_test\n",
    "CompileData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReadIndex(filename='SP500',blacklist=['BRK.B','BF.B','WRK']):\n",
    "    df = pd.read_csv('{}.csv'.format(filename))\n",
    "    ListOfTickers = df['Symbol'].tolist()\n",
    "    for ticker in blacklist:\n",
    "        ListOfTickers.remove(ticker)\n",
    "    return ListOfTickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[39572000000,\n",
       "  39572000000,\n",
       "  36171000000,\n",
       "  36171000000,\n",
       "  48140000000,\n",
       "  53851000000,\n",
       "  47501000000,\n",
       "  47501000000,\n",
       "  47501000000,\n",
       "  47501000000,\n",
       "  47501000000,\n",
       "  47501000000,\n",
       "  53926000000,\n",
       "  57057000000,\n",
       "  64725000000,\n",
       "  75183000000,\n",
       "  75183000000,\n",
       "  75183000000,\n",
       "  75183000000,\n",
       "  75183000000,\n",
       "  86742000000,\n",
       "  94904000000,\n",
       "  106758000000,\n",
       "  116371000000,\n",
       "  116371000000,\n",
       "  116371000000,\n",
       "  116371000000,\n",
       "  116371000000,\n",
       "  116371000000,\n",
       "  138681000000,\n",
       "  150934000000,\n",
       "  162896000000,\n",
       "  176064000000,\n",
       "  176064000000,\n",
       "  176064000000,\n",
       "  176064000000,\n",
       "  176064000000,\n",
       "  176064000000,\n",
       "  196088000000,\n",
       "  194743000000,\n",
       "  199856000000,\n",
       "  207000000000,\n",
       "  207000000000,\n",
       "  207000000000,\n",
       "  207000000000,\n",
       "  207000000000,\n",
       "  207000000000,\n",
       "  225184000000,\n",
       "  205989000000,\n",
       "  222520000000,\n",
       "  231839000000,\n",
       "  231839000000,\n",
       "  231839000000,\n",
       "  231839000000,\n",
       "  231839000000,\n",
       "  231839000000,\n",
       "  261894000000,\n",
       "  261194000000,\n",
       "  273151000000,\n",
       "  290479000000,\n",
       "  290479000000,\n",
       "  290479000000,\n",
       "  290479000000,\n",
       "  290345000000,\n",
       "  293284000000,\n",
       "  305277000000,\n",
       "  305602000000,\n",
       "  321686000000,\n",
       "  321686000000,\n",
       "  321686000000,\n",
       "  321686000000,\n",
       "  321686000000,\n",
       "  331141000000,\n",
       "  334532000000,\n",
       "  345173000000,\n",
       "  375319000000,\n",
       "  375319000000,\n",
       "  375319000000,\n",
       "  375319000000,\n",
       "  375319000000,\n",
       "  406794000000,\n",
       "  367502000000,\n",
       "  349197000000,\n",
       "  365725000000,\n",
       "  365725000000,\n",
       "  365725000000,\n",
       "  365725000000,\n",
       "  365725000000,\n",
       "  373719000000,\n",
       "  341998000000,\n",
       "  322239000000,\n",
       "  338516000000,\n",
       "  338516000000,\n",
       "  338516000000,\n",
       "  338516000000,\n",
       "  338516000000,\n",
       "  340618000000,\n",
       "  320400000000,\n",
       "  317344000000,\n",
       "  323888000000,\n",
       "  323888000000,\n",
       "  323888000000,\n",
       "  323888000000,\n",
       "  323888000000,\n",
       "  354054000000,\n",
       "  337158000000,\n",
       "  329840000000,\n",
       "  351002000000,\n",
       "  351002000000,\n",
       "  351002000000,\n",
       "  351002000000,\n",
       "  351002000000,\n",
       "  381191000000,\n",
       "  350662000000,\n",
       "  336309000000,\n",
       "  352755000000,\n",
       "  352755000000,\n",
       "  352755000000,\n",
       "  352755000000,\n",
       "  352755000000,\n",
       "  346747000000,\n",
       "  332160000000,\n",
       "  335038000000,\n",
       "  352583000000,\n",
       "  352583000000,\n",
       "  352583000000,\n",
       "  352583000000,\n",
       "  353514000000,\n",
       "  337411000000,\n",
       "  331612000000]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function to get the CIK of a company from the SEC database\n",
    "def get_cik(ticker):\n",
    "    ticker_symbol = ticker.upper()\n",
    "\n",
    "    # getting all the companies ticker and CIK from the SEC database as a dictionary\n",
    "    companyTickers = requests.get('https://www.sec.gov/files/company_tickers.json', headers={'User-Agent': \"testing@gmail.com\"}).json().values()\n",
    "\n",
    "    # returns {'cik_str': 320193, 'ticker': 'AAPL', 'title': 'Apple Inc.'} for each company\n",
    "    for company in companyTickers:\n",
    "        if company['ticker'] == ticker_symbol:\n",
    "            return(company)\n",
    "\n",
    "    return('Ticker CIK not found in SEC database')\n",
    "\n",
    "# function to get the SEC financial reports of a company\n",
    "def sec_filings(ticker,metrics=['Assets']):\n",
    "\n",
    "    ticker_symbol = ticker.upper()\n",
    "\n",
    "    # grab CIK and fill leading zeroes\n",
    "    cik = str(get_cik(ticker_symbol)['cik_str']).zfill(10)\n",
    "\n",
    "    filingData = requests.get(f'https://data.sec.gov/api/xbrl/companyfacts/CIK{cik}.json',headers={'User-Agent': \"testing@gmail.com\"}).json()\n",
    "\n",
    "    # used to check the key names for category of data\n",
    "    # print(filingData['facts']['us-gaap'].keys())\n",
    "\n",
    "    # this is how to grab the data from the json api\n",
    "    metricList = []\n",
    "    for metric in metrics:\n",
    "        valList = []\n",
    "        for i in filingData['facts']['us-gaap'][f'{metric}']['units']['USD']:\n",
    "        # ['USD/shares']:\n",
    "            val = i['val']\n",
    "            valList.append(val)\n",
    "        metricList.append(valList)\n",
    "\n",
    "    return metricList\n",
    "sec_filings('aapl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MMM\n",
      "AOS\n",
      "ABT\n",
      "ABBV\n",
      "ACN\n",
      "ADBE\n",
      "AMD\n",
      "AES\n",
      "AFL\n",
      "A\n",
      "APD\n",
      "ABNB\n",
      "AKAM\n",
      "ALB\n",
      "ARE\n",
      "ALGN\n",
      "ALLE\n",
      "LNT\n",
      "ALL\n",
      "GOOGL\n",
      "GOOG\n",
      "MO\n",
      "AMZN\n",
      "AMCR\n",
      "AEE\n",
      "AAL\n",
      "AEP\n",
      "AXP\n",
      "AIG\n",
      "AMT\n",
      "AWK\n",
      "AMP\n",
      "AME\n",
      "AMGN\n",
      "APH\n",
      "ADI\n",
      "ANSS\n",
      "AON\n",
      "APA\n",
      "AAPL\n",
      "AMAT\n",
      "APTV\n",
      "ACGL\n",
      "ADM\n",
      "ANET\n",
      "AJG\n",
      "AIZ\n",
      "T\n",
      "ATO\n",
      "ADSK\n",
      "ADP\n",
      "AZO\n",
      "AVB\n",
      "AVY\n",
      "AXON\n",
      "BKR\n",
      "BALL\n",
      "BAC\n",
      "BK\n",
      "BBWI\n",
      "BAX\n",
      "BDX\n",
      "BBY\n",
      "BIO\n",
      "TECH\n",
      "BIIB\n",
      "BLK\n",
      "BX\n",
      "BA\n",
      "BKNG\n",
      "BWA\n",
      "BXP\n",
      "BSX\n",
      "BMY\n",
      "AVGO\n",
      "BR\n",
      "BRO\n",
      "BLDR\n",
      "BG\n",
      "CDNS\n",
      "CZR\n",
      "CPT\n",
      "CPB\n",
      "COF\n",
      "CAH\n",
      "KMX\n",
      "CCL\n",
      "CARR\n",
      "CTLT\n",
      "CAT\n",
      "CBOE\n",
      "CBRE\n",
      "CDW\n",
      "CE\n",
      "COR\n",
      "CNC\n",
      "CNP\n",
      "CF\n",
      "CHRW\n",
      "CRL\n",
      "SCHW\n",
      "CHTR\n",
      "CVX\n",
      "CMG\n",
      "CB\n",
      "CHD\n",
      "CI\n",
      "CINF\n",
      "CTAS\n",
      "CSCO\n",
      "C\n",
      "CFG\n",
      "CLX\n",
      "CME\n",
      "CMS\n",
      "KO\n",
      "CTSH\n",
      "CL\n",
      "CMCSA\n",
      "CMA\n",
      "CAG\n",
      "COP\n",
      "ED\n",
      "STZ\n",
      "CEG\n",
      "COO\n",
      "CPRT\n",
      "GLW\n",
      "CPAY\n",
      "CTVA\n",
      "CSGP\n",
      "COST\n",
      "CTRA\n",
      "CCI\n",
      "CSX\n",
      "CMI\n",
      "CVS\n",
      "DHR\n",
      "DRI\n",
      "DVA\n",
      "DAY\n",
      "DECK\n",
      "DE\n",
      "DAL\n",
      "DVN\n",
      "DXCM\n",
      "FANG\n",
      "DLR\n",
      "DFS\n",
      "DG\n",
      "DLTR\n",
      "D\n",
      "DPZ\n",
      "DOV\n",
      "DOW\n",
      "DHI\n",
      "DTE\n",
      "DUK\n",
      "DD\n",
      "EMN\n",
      "ETN\n",
      "EBAY\n",
      "ECL\n",
      "EIX\n",
      "EW\n",
      "EA\n",
      "ELV\n",
      "LLY\n",
      "EMR\n",
      "ENPH\n",
      "ETR\n",
      "EOG\n",
      "EPAM\n",
      "EQT\n",
      "EFX\n",
      "EQIX\n",
      "EQR\n",
      "ESS\n",
      "EL\n",
      "ETSY\n",
      "EG\n",
      "EVRG\n",
      "ES\n",
      "EXC\n",
      "EXPE\n",
      "EXPD\n",
      "EXR\n",
      "XOM\n",
      "FFIV\n",
      "FDS\n",
      "FICO\n",
      "FAST\n",
      "FRT\n",
      "FDX\n",
      "FIS\n",
      "FITB\n",
      "FSLR\n",
      "FE\n",
      "FI\n",
      "FMC\n",
      "F\n",
      "FTNT\n",
      "FTV\n",
      "FOXA\n",
      "FOX\n",
      "BEN\n",
      "FCX\n",
      "GRMN\n",
      "IT\n",
      "GE\n",
      "GEHC\n",
      "GEV\n",
      "GEN\n",
      "GNRC\n",
      "GD\n",
      "GIS\n",
      "GM\n",
      "GPC\n",
      "GILD\n",
      "GPN\n",
      "GL\n",
      "GS\n",
      "HAL\n",
      "HIG\n",
      "HAS\n",
      "HCA\n",
      "DOC\n",
      "HSIC\n",
      "HSY\n",
      "HES\n",
      "HPE\n",
      "HLT\n",
      "HOLX\n",
      "HD\n",
      "HON\n",
      "HRL\n",
      "HST\n",
      "HWM\n",
      "HPQ\n",
      "HUBB\n",
      "HUM\n",
      "HBAN\n",
      "HII\n",
      "IBM\n",
      "IEX\n",
      "IDXX\n",
      "ITW\n",
      "ILMN\n",
      "INCY\n",
      "IR\n",
      "PODD\n",
      "INTC\n",
      "ICE\n",
      "IFF\n",
      "IP\n",
      "IPG\n",
      "INTU\n",
      "ISRG\n",
      "IVZ\n",
      "INVH\n",
      "IQV\n",
      "IRM\n",
      "JBHT\n",
      "JBL\n",
      "JKHY\n",
      "J\n",
      "JNJ\n",
      "JCI\n",
      "JPM\n",
      "JNPR\n",
      "K\n",
      "KVUE\n",
      "KDP\n",
      "KEY\n",
      "KEYS\n",
      "KMB\n",
      "KIM\n",
      "KMI\n",
      "KLAC\n",
      "KHC\n",
      "KR\n",
      "LHX\n",
      "LH\n",
      "LRCX\n",
      "LW\n",
      "LVS\n",
      "LDOS\n",
      "LEN\n",
      "LIN\n",
      "LYV\n",
      "LKQ\n",
      "LMT\n",
      "L\n",
      "LOW\n",
      "LULU\n",
      "LYB\n",
      "MTB\n",
      "MRO\n",
      "MPC\n",
      "MKTX\n",
      "MAR\n",
      "MMC\n",
      "MLM\n",
      "MAS\n",
      "MA\n",
      "MTCH\n",
      "MKC\n",
      "MCD\n",
      "MCK\n",
      "MDT\n",
      "MRK\n",
      "META\n",
      "MET\n",
      "MTD\n",
      "MGM\n",
      "MCHP\n",
      "MU\n",
      "MSFT\n",
      "MAA\n",
      "MRNA\n",
      "MHK\n",
      "MOH\n",
      "TAP\n",
      "MDLZ\n",
      "MPWR\n",
      "MNST\n",
      "MCO\n",
      "MS\n",
      "MOS\n",
      "MSI\n",
      "MSCI\n",
      "NDAQ\n",
      "NTAP\n",
      "NFLX\n",
      "NEM\n",
      "NWSA\n",
      "NWS\n",
      "NEE\n",
      "NKE\n",
      "NI\n",
      "NDSN\n",
      "NSC\n",
      "NTRS\n",
      "NOC\n",
      "NCLH\n",
      "NRG\n",
      "NUE\n",
      "NVDA\n",
      "NVR\n",
      "NXPI\n",
      "ORLY\n",
      "OXY\n",
      "ODFL\n",
      "OMC\n",
      "ON\n",
      "OKE\n",
      "ORCL\n",
      "OTIS\n",
      "PCAR\n",
      "PKG\n",
      "PANW\n",
      "PARA\n",
      "PH\n",
      "PAYX\n",
      "PAYC\n",
      "PYPL\n",
      "PNR\n",
      "PEP\n",
      "PFE\n",
      "PCG\n",
      "PM\n",
      "PSX\n",
      "PNW\n",
      "PNC\n",
      "POOL\n",
      "PPG\n",
      "PPL\n",
      "PFG\n",
      "PG\n",
      "PGR\n",
      "PLD\n",
      "PRU\n",
      "PEG\n",
      "PTC\n",
      "PSA\n",
      "PHM\n",
      "QRVO\n",
      "PWR\n",
      "QCOM\n",
      "DGX\n",
      "RL\n",
      "RJF\n",
      "RTX\n",
      "O\n",
      "REG\n",
      "REGN\n",
      "RF\n",
      "RSG\n",
      "RMD\n",
      "RVTY\n",
      "RHI\n",
      "ROK\n",
      "ROL\n",
      "ROP\n",
      "ROST\n",
      "RCL\n",
      "SPGI\n",
      "CRM\n",
      "SBAC\n",
      "SLB\n",
      "STX\n",
      "SRE\n",
      "NOW\n",
      "SHW\n",
      "SPG\n",
      "SWKS\n",
      "SJM\n",
      "SNA\n",
      "SOLV\n",
      "SO\n",
      "LUV\n",
      "SWK\n",
      "SBUX\n",
      "STT\n",
      "STLD\n",
      "STE\n",
      "SYK\n",
      "SMCI\n",
      "SYF\n",
      "SNPS\n",
      "SYY\n",
      "TMUS\n",
      "TROW\n",
      "TTWO\n",
      "TPR\n",
      "TRGP\n",
      "TGT\n",
      "TEL\n",
      "TDY\n",
      "TFX\n",
      "TER\n",
      "TSLA\n",
      "TXN\n",
      "TXT\n",
      "TMO\n",
      "TJX\n",
      "TSCO\n",
      "TT\n",
      "TDG\n",
      "TRV\n",
      "TRMB\n",
      "TFC\n",
      "TYL\n",
      "TSN\n",
      "USB\n",
      "UBER\n",
      "UDR\n",
      "ULTA\n",
      "UNP\n",
      "UAL\n",
      "UPS\n",
      "URI\n",
      "UNH\n",
      "UHS\n",
      "VLO\n",
      "VTR\n",
      "VLTO\n",
      "VRSN\n",
      "VRSK\n",
      "VZ\n",
      "VRTX\n",
      "VTRS\n",
      "VICI\n",
      "V\n",
      "VST\n",
      "VMC\n",
      "WRB\n",
      "GWW\n",
      "WAB\n",
      "WBA\n",
      "WMT\n",
      "DIS\n",
      "WBD\n",
      "WM\n",
      "WAT\n",
      "WEC\n",
      "WFC\n",
      "WELL\n",
      "WST\n",
      "WDC\n",
      "WY\n",
      "WMB\n",
      "WTW\n",
      "WYNN\n",
      "XEL\n",
      "XYL\n",
      "YUM\n",
      "ZBRA\n",
      "ZBH\n",
      "ZTS\n",
      "ZION\n",
      "ZTS\n"
     ]
    }
   ],
   "source": [
    "def find_intersection(list1, list2):\n",
    "    intersection = list(set(list1) & set(list2))\n",
    "    return intersection\n",
    "\n",
    "f = list(sec_filings('MMM'))\n",
    "yuh =['NetCashProvidedByUsedInFinancingActivities', 'NetCashProvidedByUsedInInvestingActivities', 'Assets', 'LiabilitiesAndStockholdersEquity']\n",
    "\n",
    "for ticker in ReadIndex():\n",
    "    print(ticker)\n",
    "    e = sec_filings(ticker,yuh)\n",
    "\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m cik \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[43mget_cik\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mWRK\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcik_str\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\u001b[38;5;241m.\u001b[39mzfill(\u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m      3\u001b[0m filingData \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://data.sec.gov/api/xbrl/companyfacts/CIK\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcik\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.json\u001b[39m\u001b[38;5;124m'\u001b[39m,headers\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUser-Agent\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtesting@gmail.com\u001b[39m\u001b[38;5;124m\"\u001b[39m})\u001b[38;5;241m.\u001b[39mjson()\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(filingData[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfacts\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mus-gaap\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mkeys())\n",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers, not 'str'"
     ]
    }
   ],
   "source": [
    "cik = str(get_cik('WRK')['cik_str']).zfill(10)\n",
    "\n",
    "filingData = requests.get(f'https://data.sec.gov/api/xbrl/companyfacts/CIK{cik}.json',headers={'User-Agent': \"testing@gmail.com\"}).json()\n",
    "\n",
    "print(filingData['facts']['us-gaap'].keys())\n",
    "# ['EarningsPerShareBasic']['units']['USD/shares']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val,filed = [],[]\n",
    "val,filed = np.array(val), np.array(filed)\n",
    "for i in filingData['facts']['us-gaap']['EarningsPerShareBasic']['units']['USD/shares']:\n",
    "    val = np.append(i['val'],val)\n",
    "    filed = np.append(i['filed'],filed)\n",
    "    \n",
    "val,filed = pd.DataFrame(val),pd.DataFrame(filed)\n",
    "\n",
    "df = pd.concat([val,filed],axis=1)\n",
    "df.columns = ['val','filed']\n",
    "df = df.set_index(df['filed'])\n",
    "df.drop(columns=['filed'],inplace=True)\n",
    "df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
